#!/usr/bin/env python

# --------------------------------------------------------
# R-FCN
# Copyright (c) 2016 Yuwen Xiong
# Licensed under The MIT License [see LICENSE for details]
# Written by Yuwen Xiong
# --------------------------------------------------------

"""
Demo script showing detections in sample images.

See README.md for installation instructions before running.
"""

# ----------------------------------
#                             bugfix
# ----------------------------------

import matplotlib
matplotlib.use('Agg')

# ----------------------------------
#                 PYTHONPATH hacking
# ----------------------------------
from os.path import join as pjoin
import os, sys

def add_path(path):
    if path not in sys.path:
        sys.path.insert(0, path)

base = os.path.expanduser('~/coding/libs/caffes/py-R-FCN')
caffe_path = pjoin(base, 'caffe/python')
zsvision_path = os.path.expanduser('~/coding/src/zsvision/python')
lib_path = pjoin(base, 'lib')
add_path(caffe_path)
add_path(lib_path)
add_path(zsvision_path)

import ipdb
import caffe, cv2
from fast_rcnn.config import cfg
from utils.blob import im_list_to_blob
from fast_rcnn.nms_wrapper import nms
from utils.timer import Timer
import matplotlib.pyplot as plt
import numpy as np
import scipy.io as sio
from fast_rcnn.bbox_transform import clip_boxes, bbox_transform_inv

from zsvision.zs_iterm import zs_dispFig

model_dir = '/users/albanie/coding/libs/matconvnets/contrib-matconvnet/data/r-fcn-caffe-models'
vl_rootnn = os.path.expanduser('~/coding/libs/matconvnets/contrib-matconvnet')
im_path = pjoin(vl_rootnn, 'contrib/mcnRFCN/misc/python', '000067.jpg')
net_name = 'ResNet-50' ; fname = 'blobs-{}.mat'.format(net_name)
blob_save_path = pjoin(vl_rootnn, 'contrib/mcnRFCN/feats', fname)
im_minus_path = pjoin(vl_rootnn, 'contrib/mcnRFCN/feats', 'im-minus.mat')

CLASSES = ('__background__',
           'aeroplane', 'bicycle', 'bird', 'boat',
           'bottle', 'bus', 'car', 'cat', 'chair',
           'cow', 'diningtable', 'dog', 'horse',
           'motorbike', 'person', 'pottedplant',
           'sheep', 'sofa', 'train', 'tvmonitor')

def _get_image_blob(im):
    """Converts an image into a network input.

    Arguments:
        im (ndarray): a color image in BGR order

    Returns:
        blob (ndarray): a data blob holding an image pyramid
        im_scale_factors (list): list of image scales (relative to im) used
            in the image pyramid
    """
    im_orig = im.astype(np.float32, copy=True)
    im_orig -= cfg.PIXEL_MEANS
    sio.savemat(im_minus_path, {'im_minus':im_orig}, oned_as='column')

    im_shape = im_orig.shape
    im_size_min = np.min(im_shape[0:2])
    im_size_max = np.max(im_shape[0:2])

    processed_ims = []
    im_scale_factors = []

    for target_size in cfg.TEST.SCALES:
        im_scale = float(target_size) / float(im_size_min)
        # Prevent the biggest axis from being more than MAX_SIZE
        if np.round(im_scale * im_size_max) > cfg.TEST.MAX_SIZE:
            im_scale = float(cfg.TEST.MAX_SIZE) / float(im_size_max)
        im = cv2.resize(im_orig, None, None, fx=im_scale, fy=im_scale,
                        interpolation=cv2.INTER_LINEAR)
        im_scale_factors.append(im_scale)
        processed_ims.append(im)

    # Create a blob to hold the input images
    blob = im_list_to_blob(processed_ims)

    return blob, np.array(im_scale_factors)

def _get_blobs(im, rois):
    """Convert an image and RoIs within that image into network inputs."""
    blobs = {'data' : None, 'rois' : None}
    blobs['data'], im_scale_factors = _get_image_blob(im)
    if not cfg.TEST.HAS_RPN:
        blobs['rois'] = _get_rois_blob(rois, im_scale_factors)
    return blobs, im_scale_factors

def im_detect(net, im, boxes=None):
    """Detect object classes in an image given object proposals.

    Arguments:
        net (caffe.Net): Fast R-CNN network to use
        im (ndarray): color image to test (in BGR order)
        boxes (ndarray): R x 4 array of object proposals or None (for RPN)

    Returns:
        scores (ndarray): R x K array of object class scores (K includes
            background as object category 0)
        boxes (ndarray): R x (4*K) array of predicted bounding boxes
    """
    blobs, im_scales = _get_blobs(im, boxes)

    # When mapping from image ROIs to feature map ROIs, there's some aliasing
    # (some distinct image ROIs get mapped to the same feature ROI).
    # Here, we identify duplicate feature ROIs, so we only compute features
    # on the unique subset.
    if cfg.DEDUP_BOXES > 0 and not cfg.TEST.HAS_RPN:
        v = np.array([1, 1e3, 1e6, 1e9, 1e12])
        hashes = np.round(blobs['rois'] * cfg.DEDUP_BOXES).dot(v)
        _, index, inv_index = np.unique(hashes, return_index=True,
                                        return_inverse=True)
        blobs['rois'] = blobs['rois'][index, :]
        boxes = boxes[index, :]

    if cfg.TEST.HAS_RPN:
        im_blob = blobs['data']
        blobs['im_info'] = np.array(
            [[im_blob.shape[2], im_blob.shape[3], im_scales[0]]],
            dtype=np.float32)

    # reshape network inputs
    net.blobs['data'].reshape(*(blobs['data'].shape))
    if cfg.TEST.HAS_RPN:
        net.blobs['im_info'].reshape(*(blobs['im_info'].shape))
    else:
        net.blobs['rois'].reshape(*(blobs['rois'].shape))

    # do forward
    forward_kwargs = {'data': blobs['data'].astype(np.float32, copy=False)}
    if cfg.TEST.HAS_RPN:
        forward_kwargs['im_info'] = blobs['im_info'].astype(np.float32, copy=False)
    else:
        forward_kwargs['rois'] = blobs['rois'].astype(np.float32, copy=False)
    # blobs_out = net.forward(**forward_kwargs) # no value is returned, 
    # since it gets swallowed by debug layer
    net.forward(**forward_kwargs)

    if cfg.TEST.HAS_RPN:
        assert len(im_scales) == 1, "Only single-image batch implemented"
        rois = net.blobs['rois'].data.copy()
        # unscale back to raw image space
        boxes = rois[:, 1:5] / im_scales[0]

    if cfg.TEST.SVM:
        # use the raw scores before softmax under the assumption they
        # were trained as linear SVMs
        scores = net.blobs['cls_score'].data
    else:
        # use softmax estimated probabilities
        scores = net.blobs['cls_prob'].data

    if cfg.TEST.BBOX_REG:
        # Apply bounding-box regression deltas
        box_deltas = net.blobs['bbox_pred'].data
        pred_boxes = bbox_transform_inv(boxes, box_deltas)
        pred_boxes = clip_boxes(pred_boxes, im.shape)
    else:
        # Simply repeat the boxes, once for each class
        pred_boxes = np.tile(boxes, (1, scores.shape[1]))

    if cfg.DEDUP_BOXES > 0 and not cfg.TEST.HAS_RPN:
        # Map scores and predictions back to the original set of boxes
        scores = scores[inv_index, :]
        pred_boxes = pred_boxes[inv_index, :]

    return scores, pred_boxes, net.blobs



def vis_detections(im, class_name, dets, thresh=0.5):
    """Draw detected bounding boxes."""
    inds = np.where(dets[:, -1] >= thresh)[0]
    if len(inds) == 0:
        return

    im = im[:, :, (2, 1, 0)]
    fig, ax = plt.subplots(figsize=(12, 12))
    ax.imshow(im, aspect='equal')
    for i in inds:
        bbox = dets[i, :4]
        score = dets[i, -1]

        ax.add_patch(
            plt.Rectangle((bbox[0], bbox[1]),
                          bbox[2] - bbox[0],
                          bbox[3] - bbox[1], fill=False,
                          edgecolor='red', linewidth=3.5)
            )
        ax.text(bbox[0], bbox[1] - 2,
                '{:s} {:.3f}'.format(class_name, score),
                bbox=dict(facecolor='blue', alpha=0.5),
                fontsize=14, color='white')

    ax.set_title(('{} detections with '
                  'p({} | box) >= {:.1f}').format(class_name, class_name,
                                                  thresh),
                  fontsize=14)
    plt.axis('off')
    plt.tight_layout()
    plt.draw()

def demo(net, im_path, blob_save_path):
    """Detect object classes in an image using pre-computed object proposals."""
    im = cv2.imread(im_path)

    # Detect all object classes and regress object bounds
    timer = Timer()
    timer.tic() ; 
    scores, boxes, blobs = im_detect(net, im) ; 
    timer.toc()
    blobs_data = dict()
    for key in blobs:
        new_key = key.replace('/', '_')
        blobs_data[new_key] = blobs[key].data
    ipdb.set_trace()
    sio.savemat(blob_save_path, blobs_data, oned_as='column')
    
    msg = 'Detection took {:.3f}s for {:d} object proposals'
    print(msg.format(timer.total_time, boxes.shape[0]))

    # Visualize detections for each class
    CONF_THRESH = 0.8 ; NMS_THRESH = 0.3
    for cls_ind, cls in enumerate(CLASSES[1:]):
        cls_ind += 1 # because we skipped background
        cls_boxes = boxes[:, 4*cls_ind:4*(cls_ind + 1)]
        cls_scores = scores[:, cls_ind]
        dets = np.hstack((cls_boxes,
                          cls_scores[:, np.newaxis])).astype(np.float32)
        keep = nms(dets, NMS_THRESH)
        dets = dets[keep, :]
        vis_detections(im, cls, dets, thresh=CONF_THRESH)

cfg.TEST.HAS_RPN = True  # Use RPN for proposals

if net_name == 'ResNet-50':
    pt = 'resnet50_rfcn_pascal_debug.proto'
    model = 'resnet50_rfcn_final.caffemodel'
else:
    raise ValueError('{} not recognised'.format(net_name))
 
prototxt = pjoin(model_dir, 'proto', pt)
caffemodel = pjoin(model_dir, 'weights', model)

if not os.path.isfile(caffemodel):
    raise IOError(('{:s} not found.\nDid you run ./data/script/'
                   'fetch_faster_rcnn_models.sh?').format(caffemodel))

# psroi pooling only works on gpu
caffe.set_mode_gpu()
caffe.set_device(2)
cfg.GPU_ID = 2
net = caffe.Net(prototxt, caffemodel, caffe.TEST)

demo(net, im_path, blob_save_path)
plt.show()
zs_dispFig() 
